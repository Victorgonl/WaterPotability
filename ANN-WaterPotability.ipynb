{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso: Redes Neurais e Deep Learning\n",
    "\n",
    "Prof. Denilson Alves Pereira \n",
    "https://sites.google.com/ufla.br/denilsonpereira/ \n",
    "Departamento de Ciência da Computação - \n",
    "Instituto de Ciências Exatas e Tecnológicas - \n",
    "Universidade Federal de Lavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elaborar uma rede neural artifical (ANN) para predizer se uma amostra de água é considerada potável, com base em medidas contidas no dataset disponível em https://www.kaggle.com/datasets/adityakadiwal/water-potability\n",
    "\n",
    "Os parâmetros de entrada para o problema são:\n",
    "- valor do PH\n",
    "- dureza, causada por cálcio e sais de magnésio\n",
    "- total de sólidos dissolvidos\n",
    "- concentração de cloraminas\n",
    "- concentração de sulfato\n",
    "- condutividade\n",
    "- concentração de carbono orgânico\n",
    "- concentração de trialometanos\n",
    "- turbidez\n",
    "\n",
    "E a saída é binária de acordo com que a água seja potável ou não."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # para computação científica\n",
    "import tensorflow as tf # para computação númerica nos dados\n",
    "from tensorflow import keras # para deep learning\n",
    "import pandas as pd # para trabalhar com análise de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento dos dados de treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('potabilidade.csv') # lẽ o dataset\n",
    "data.head(10) # mostra as 10 primeiras linhas do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removendo linhas que possuem ausência de dados no dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A forma de lidar com a ausência de dados foi remover a linha completa onde um ou mais valores nulos (NaN) forem encontrados. A consequência disso é uma enorme redução do dataset disponível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=\"index\", how='any', inplace=True) # remove linhas onde for encontrado valor nulo\n",
    "data.head(10) # mostra as 10 primeiras linhas do dataset após a remocão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando as entradas e saídas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"Potability\", axis=1)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saídas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[\"Potability\"]\n",
    "Y.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando conjuntos de treino e teste para as entradas e saídas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set_X, test_set_X, train_set_Y, test_set_Y = train_test_split(X, Y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padronizando os atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_set_X = scaler.fit_transform(train_set_X)\n",
    "test_set_X  = scaler.fit_transform(test_set_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo número de atributos e exemplos de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = train_set_X.shape[1] # número de atributos\n",
    "m = train_set_X.shape[0] # número de exemplos para treinamento\n",
    "\n",
    "print (\"Número de atributos: n = \" + str(n))\n",
    "print (\"Número de exemplos para treinamento: m = \" + str(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição do modelo\n",
    "- Camada de entrada: de acordo com as 9 entradas do problema\n",
    "- Camada 1: 7 neurônios, função de ativação *ReLu*\n",
    "- Camada 2 (saída): 1 neurônio, função de ativação *Sigmoid*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=n)\n",
    "x = keras.layers.Dense(units=7, activation=\"relu\")(inputs)\n",
    "outputs = keras.layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"RMSprop\", loss=\"mean_absolute_error\", metrics=[\"accuracy\", \"Precision\", \"Recall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_set_X, train_set_Y, batch_size=32, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, prec, rec = model.evaluate(test_set_X, test_set_Y)\n",
    "print(\"Loss: %.2f\" % loss, \"\\nAccuracy: %.2f\" % acc, \"\\nPrecision: %.2f\" % prec, \"\\nRecall: %.2f\" % rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_set_X)\n",
    "print(\"Predição: \", [round(x[0]) for x in predictions])\n",
    "print()\n",
    "print(\"Correto: \", [round(x) for x in test_set_Y])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
